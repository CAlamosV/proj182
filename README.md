<img width="1359" alt="Screen Shot 2023-11-28 at 14 22 53" src="https://github.com/CAlamosV/proj182/assets/66649572/49e2dcc5-f739-41e5-a2cb-42d2d421e050">

# In-Context Learning of Intuitive Physics in Vision Transformers
### Cristian Alamos, Masha Bondarenko, Martin Guo, Alex Nguyen, Max Vogel

## **Abstract**
This study delves into the in-context learning (ICL) phenomenon of transformers, extending their adaptability to novel tasks without parameter updates. While transformers exhibit near Bayes-optimal in-context learning for simple function classes in previous research, our focus shifts to evaluating the potential of vision transformers in mastering intuitive physics in-context. Specifically, we train a vision transformer to predict the subsequent frame in a sequence of images depicting a bouncing ball, incorporating variations in gravity strength and ball elasticity. The assessment involves testing the model's generalization to unseen parameter combinations, contributing valuable insights into vision transformers' in-context learning capabilities within the realm of intuitive physics.
